{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T13:26:15.553153Z",
     "start_time": "2025-07-01T13:26:12.900726Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载CIFAR-10数据集...\n",
      "使用设备: cpu\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 91\u001B[0m\n\u001B[0;32m     88\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     89\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m使用设备: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdevice\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 91\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mImprovedCNN\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m模型参数数量: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28msum\u001B[39m(p\u001B[38;5;241m.\u001B[39mnumel()\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mp\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39mmodel\u001B[38;5;241m.\u001B[39mparameters())\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m,\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     94\u001B[0m \u001B[38;5;66;03m# 3. 训练配置\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[2], line 61\u001B[0m, in \u001B[0;36mImprovedCNN.__init__\u001B[1;34m(self, num_classes)\u001B[0m\n\u001B[0;32m     59\u001B[0m         \u001B[38;5;66;03m# 池化层和激活函数\u001B[39;00m\n\u001B[0;32m     60\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpool \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mMaxPool2d(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m---> 61\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu \u001B[38;5;241m=\u001B[39m \u001B[43mader\u001B[49m(testset, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m256\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, num_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m     63\u001B[0m \u001B[38;5;66;03m# 2. 定义改进的CNNnn.ReLU(inplace=True)\u001B[39;00m\n\u001B[0;32m     64\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mDropout(\u001B[38;5;241m0.5\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'ader' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723f5de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"e:\\avm\\ado\\envs\\py310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\王旭帆\\AppData\\Local\\Temp\\ipykernel_14304\\4047889382.py\", line 21, in <module>\n",
      "    from torchvision import datasets, transforms\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torchvision\\__init__.py\", line 6, in <module>\n",
      "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torchvision\\models\\__init__.py\", line 2, in <module>\n",
      "    from .convnext import *\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torchvision\\models\\convnext.py\", line 8, in <module>\n",
      "    from ..ops.misc import Conv2dNormActivation, Permute\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torchvision\\ops\\__init__.py\", line 23, in <module>\n",
      "    from .poolers import MultiScaleRoIAlign\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torchvision\\ops\\poolers.py\", line 10, in <module>\n",
      "    from .roi_align import roi_align\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torchvision\\ops\\roi_align.py\", line 4, in <module>\n",
      "    import torch._dynamo\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torch\\_dynamo\\__init__.py\", line 64, in <module>\n",
      "    torch.manual_seed = disable(torch.manual_seed)\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torch\\_dynamo\\decorators.py\", line 50, in disable\n",
      "    return DisableContext()(fn)\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py\", line 410, in __call__\n",
      "    (filename is None or trace_rules.check(fn))\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 3378, in check\n",
      "    return check_verbose(obj, is_inlined_call).skipped\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 3361, in check_verbose\n",
      "    rule = torch._dynamo.trace_rules.lookup_inner(\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 3442, in lookup_inner\n",
      "    rule = get_torch_obj_rule_map().get(obj, None)\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 2782, in get_torch_obj_rule_map\n",
      "    obj = load_object(k)\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 2811, in load_object\n",
      "    val = _load_obj_from_str(x[0])\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 2795, in _load_obj_from_str\n",
      "    return getattr(importlib.import_module(module), obj_name)\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torch\\nested\\_internal\\nested_tensor.py\", line 417, in <module>\n",
      "    values=torch.randn(3, 3, device=\"meta\"),\n",
      "e:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torch\\nested\\_internal\\nested_tensor.py:417: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  values=torch.randn(3, 3, device=\"meta\"),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载CIFAR-10数据集...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "使用设备: cuda\n",
      "模型参数数量: 2,168,746\n",
      "开始训练...\n"
     ]
    }
   ],
   "source": [
    "# 检查并安装必要的依赖\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_package(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torch.utils.data import DataLoader\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import accuracy_score, classification_report\n",
    "except ImportError as e:\n",
    "    print(f\"缺少基础包: {e}\")\n",
    "    print(\"请运行: pip install torch numpy matplotlib scikit-learn\")\n",
    "\n",
    "try:\n",
    "    from torchvision import datasets, transforms\n",
    "except ImportError:\n",
    "    print(\"正在安装torchvision和pillow...\")\n",
    "    install_package(\"torchvision\")\n",
    "    install_package(\"pillow\")\n",
    "    from torchvision import datasets, transforms\n",
    "\n",
    "# 1. 数据加载与预处理\n",
    "print(\"正在加载CIFAR-10数据集...\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "try:\n",
    "    trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "except Exception as e:\n",
    "    print(f\"数据下载失败: {e}\")\n",
    "    print(\"请检查网络连接或手动下载CIFAR-10数据集\")\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "# 2. 定义改进的CNN\n",
    "class ImprovedCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ImprovedCNN, self).__init__()\n",
    "        # 第一个卷积块\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        # 第二个卷积块\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        # 池化层和激活函数\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        # 全连接层\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 3. 设备配置\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "model = ImprovedCNN().to(device)\n",
    "print(f\"模型参数数量: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# 4. 训练配置\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# 5. 训练循环\n",
    "epochs = 15\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "print(\"开始训练...\")\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        if batch_idx % 200 == 0:\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Batch {batch_idx}, Loss: {loss.item():.4f}')\n",
    "    scheduler.step()\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_acc)\n",
    "    print(f'Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n",
    "\n",
    "# 6. 测试与评估\n",
    "print(\"开始测试...\")\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        test_loss += criterion(output, target).item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        all_preds.extend(pred.cpu().numpy().flatten())\n",
    "        all_labels.extend(target.cpu().numpy())\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = 100. * correct / len(testset)\n",
    "print(f'测试集平均损失: {test_loss:.4f}')\n",
    "print(f'测试集准确率: {test_accuracy:.2f}% ({correct}/{len(testset)})')\n",
    "\n",
    "# 7. 详细分类报告\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "print(\"\\n分类报告:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "# 8. 可视化训练过程\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses)\n",
    "plt.title('训练损失')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies)\n",
    "plt.title('训练准确率')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9. 可视化预测结果\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "for i in range(10):\n",
    "    img, true_label = testset[i]\n",
    "    pred_label = all_preds[i]\n",
    "    img_show = img * torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1) + torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    img_show = torch.clamp(img_show, 0, 1)\n",
    "    ax = axes[i//5, i%5]\n",
    "    ax.imshow(np.transpose(img_show.numpy(), (1, 2, 0)))\n",
    "    color = 'green' if true_label == pred_label else 'red'\n",
    "    ax.set_title(f\"真实: {class_names[true_label]}\\n预测: {class_names[pred_label]}\", color=color, fontsize=10)\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"程序执行完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "e78d0417",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T03:29:15.430328Z",
     "start_time": "2025-07-02T03:28:49.722884Z"
    }
   },
   "source": [
    "# 检查并安装必要的依赖\n",
    "import sys\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "def install_package(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torch.utils.data import DataLoader, Subset\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import accuracy_score, classification_report\n",
    "except ImportError as e:\n",
    "    print(f\"缺少基础包: {e}\")\n",
    "    print(\"请运行: pip install torch numpy matplotlib scikit-learn\")\n",
    "\n",
    "try:\n",
    "    from torchvision import datasets, transforms\n",
    "except ImportError:\n",
    "    print(\"正在安装torchvision和pillow...\")\n",
    "    install_package(\"torchvision\")\n",
    "    install_package(\"pillow\")\n",
    "    from torchvision import datasets, transforms\n",
    "\n",
    "# 1. 数据加载与预处理\n",
    "print(\"正在加载CIFAR-10数据集...\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "try:\n",
    "    trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "except Exception as e:\n",
    "    print(f\"数据下载失败: {e}\")\n",
    "    print(\"请检查网络连接或手动下载CIFAR-10数据集\")\n",
    "\n",
    "# 使用部分数据 - 训练集使用10%，测试集使用20%\n",
    "train_size = len(trainset) // 10  # 5000个样本\n",
    "test_size = len(testset) // 5     # 2000个样本\n",
    "\n",
    "train_indices = torch.randperm(len(trainset))[:train_size]\n",
    "test_indices = torch.randperm(len(testset))[:test_size]\n",
    "\n",
    "train_subset = Subset(trainset, train_indices)\n",
    "test_subset = Subset(testset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_subset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"使用训练样本: {len(train_subset)}\")\n",
    "print(f\"使用测试样本: {len(test_subset)}\")\n",
    "\n",
    "# 2. 定义改进的CNN\n",
    "class ImprovedCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ImprovedCNN, self).__init__()\n",
    "        # 第一个卷积块\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        # 第二个卷积块\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        # 池化层和激活函数\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        # 全连接层\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 3. 设备配置\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "model = ImprovedCNN().to(device)\n",
    "print(f\"模型参数数量: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# 4. 训练配置\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# 5. 训练循环 - 减少epochs\n",
    "epochs = 5  # 减少训练轮数\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "print(\"开始训练...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_start = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        if batch_idx % 50 == 0:  # 更频繁地打印进度\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Batch {batch_idx}, Loss: {loss.item():.4f}')\n",
    "    scheduler.step()\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_acc)\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    print(f'Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%, 时间: {epoch_time:.1f}秒')\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f'总训练时间: {total_time/60:.1f}分钟')\n",
    "\n",
    "# 6. 测试与评估\n",
    "print(\"开始测试...\")\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        test_loss += criterion(output, target).item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        all_preds.extend(pred.cpu().numpy().flatten())\n",
    "        all_labels.extend(target.cpu().numpy())\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = 100. * correct / len(test_subset)\n",
    "print(f'测试集平均损失: {test_loss:.4f}')\n",
    "print(f'测试集准确率: {test_accuracy:.2f}% ({correct}/{len(test_subset)})')\n",
    "\n",
    "# 7. 详细分类报告\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "print(\"\\n分类报告:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "# 8. 可视化训练过程\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses)\n",
    "plt.title('训练损失')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies)\n",
    "plt.title('训练准确率')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9. 可视化部分预测结果\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "for i in range(min(10, len(test_subset))):\n",
    "    img, true_label = test_subset[i]\n",
    "    pred_label = all_preds[i]\n",
    "    img_show = img * torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1) + torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    img_show = torch.clamp(img_show, 0, 1)\n",
    "    ax = axes[i//5, i%5]\n",
    "    ax.imshow(np.transpose(img_show.numpy(), (1, 2, 0)))\n",
    "    color = 'green' if true_label == pred_label else 'red'\n",
    "    ax.set_title(f\"真实: {class_names[true_label]}\\n预测: {class_names[pred_label]}\", color=color, fontsize=10)\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"程序执行完成！\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"E:\\avm\\ado\\envs\\py310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\王旭帆\\AppData\\Local\\Temp\\ipykernel_20772\\640594261.py\", line 22, in <module>\n",
      "    from torchvision import datasets, transforms\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torchvision\\__init__.py\", line 6, in <module>\n",
      "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torchvision\\models\\__init__.py\", line 2, in <module>\n",
      "    from .convnext import *\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torchvision\\models\\convnext.py\", line 8, in <module>\n",
      "    from ..ops.misc import Conv2dNormActivation, Permute\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torchvision\\ops\\__init__.py\", line 23, in <module>\n",
      "    from .poolers import MultiScaleRoIAlign\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torchvision\\ops\\poolers.py\", line 10, in <module>\n",
      "    from .roi_align import roi_align\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torchvision\\ops\\roi_align.py\", line 4, in <module>\n",
      "    import torch._dynamo\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torch\\_dynamo\\__init__.py\", line 64, in <module>\n",
      "    torch.manual_seed = disable(torch.manual_seed)\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torch\\_dynamo\\decorators.py\", line 50, in disable\n",
      "    return DisableContext()(fn)\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py\", line 410, in __call__\n",
      "    (filename is None or trace_rules.check(fn))\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 3378, in check\n",
      "    return check_verbose(obj, is_inlined_call).skipped\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 3361, in check_verbose\n",
      "    rule = torch._dynamo.trace_rules.lookup_inner(\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 3442, in lookup_inner\n",
      "    rule = get_torch_obj_rule_map().get(obj, None)\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 2782, in get_torch_obj_rule_map\n",
      "    obj = load_object(k)\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 2811, in load_object\n",
      "    val = _load_obj_from_str(x[0])\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torch\\_dynamo\\trace_rules.py\", line 2795, in _load_obj_from_str\n",
      "    return getattr(importlib.import_module(module), obj_name)\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torch\\nested\\_internal\\nested_tensor.py\", line 417, in <module>\n",
      "    values=torch.randn(3, 3, device=\"meta\"),\n",
      "E:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torch\\nested\\_internal\\nested_tensor.py:417: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  values=torch.randn(3, 3, device=\"meta\"),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载CIFAR-10数据集...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "使用训练样本: 5000\n",
      "使用测试样本: 2000\n",
      "使用设备: cuda\n",
      "模型参数数量: 2,168,746\n",
      "开始训练...\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T03:33:16.052139Z",
     "start_time": "2025-07-02T03:33:14.314232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 检查并安装必要的依赖\n",
    "import sys\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "def install_package(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torch.utils.data import DataLoader, Subset\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import accuracy_score, classification_report\n",
    "except ImportError as e:\n",
    "    print(f\"缺少基础包: {e}\")\n",
    "    install_package(\"torch numpy matplotlib scikit-learn\")\n",
    "\n",
    "try:\n",
    "    from torchvision import datasets, transforms\n",
    "except ImportError:\n",
    "    print(\"正在安装torchvision和pillow...\")\n",
    "    install_package(\"torchvision\")\n",
    "    install_package(\"pillow\")\n",
    "    from torchvision import datasets, transforms\n",
    "\n",
    "print(\"开始加载CIFAR-10数据集...\")\n",
    "\n",
    "# 1. 数据预处理 - 简化版本\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 简化的标准化\n",
    "])\n",
    "\n",
    "try:\n",
    "    trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "    print(\"数据集下载完成！\")\n",
    "except Exception as e:\n",
    "    print(f\"数据下载失败: {e}\")\n",
    "\n",
    "# 2. 大幅减少数据集大小 - 每类只用100个样本训练，20个样本测试\n",
    "def create_small_dataset(dataset, samples_per_class=100):\n",
    "    targets = np.array(dataset.targets)\n",
    "    indices = []\n",
    "    for class_id in range(10):\n",
    "        class_indices = np.where(targets == class_id)[0]\n",
    "        selected = np.random.choice(class_indices, min(samples_per_class, len(class_indices)), replace=False)\n",
    "        indices.extend(selected)\n",
    "    return Subset(dataset, indices)\n",
    "\n",
    "np.random.seed(42)  # 固定随机种子\n",
    "small_trainset = create_small_dataset(trainset, samples_per_class=100)  # 1000个训练样本\n",
    "small_testset = create_small_dataset(testset, samples_per_class=20)     # 200个测试样本\n",
    "\n",
    "train_loader = DataLoader(small_trainset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(small_testset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"训练样本数: {len(small_trainset)}\")\n",
    "print(f\"测试样本数: {len(small_testset)}\")\n",
    "\n",
    "# 3. 定义轻量级CNN模型\n",
    "class LightweightCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LightweightCNN, self).__init__()\n",
    "        # 简化的卷积层\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        # 全连接层\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, 64)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 4. 模型初始化\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "model = LightweightCNN().to(device)\n",
    "print(f\"模型参数数量: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# 5. 训练配置\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "# 6. 快速训练 - 只训练3个epoch\n",
    "epochs = 3\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "print(\"开始快速训练...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_acc)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f'训练完成！用时: {training_time:.1f}秒')\n",
    "\n",
    "# 7. 快速测试\n",
    "print(\"开始测试...\")\n",
    "model.eval()\n",
    "correct = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += pred.eq(target).sum().item()\n",
    "        all_preds.extend(pred.cpu().numpy())\n",
    "        all_labels.extend(target.cpu().numpy())\n",
    "\n",
    "test_accuracy = 100. * correct / len(small_testset)\n",
    "print(f'测试准确率: {test_accuracy:.2f}% ({correct}/{len(small_testset)})')\n",
    "\n",
    "# 8. 可视化训练过程\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, 'b-', marker='o')\n",
    "plt.title('训练损失')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, 'r-', marker='s')\n",
    "plt.title('训练准确率')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9. 可视化预测结果\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "for i in range(10):\n",
    "    if i >= len(small_testset):\n",
    "        break\n",
    "\n",
    "    # 获取测试数据\n",
    "    img, true_label = small_testset[i]\n",
    "    pred_label = all_preds[i]\n",
    "\n",
    "    # 反标准化显示图像\n",
    "    img_show = img * 0.5 + 0.5\n",
    "    img_show = torch.clamp(img_show, 0, 1)\n",
    "\n",
    "    ax = axes[i//5, i%5]\n",
    "    ax.imshow(np.transpose(img_show.numpy(), (1, 2, 0)))\n",
    "\n",
    "    # 设置标题颜色\n",
    "    color = 'green' if true_label == pred_label else 'red'\n",
    "    ax.set_title(f\"真实: {class_names[true_label]}\\n预测: {class_names[pred_label]}\",\n",
    "                color=color, fontsize=10)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 10. 简化的分类报告\n",
    "print(\"\\n各类别准确率:\")\n",
    "for i in range(10):\n",
    "    class_mask = np.array(all_labels) == i\n",
    "    if np.sum(class_mask) > 0:\n",
    "        class_acc = np.mean(np.array(all_preds)[class_mask] == i) * 100\n",
    "        print(f\"{class_names[i]}: {class_acc:.1f}%\")\n",
    "\n",
    "print(f\"\\n总体准确率: {test_accuracy:.2f}%\")\n",
    "print(\"训练完成！这是一个轻量级版本，适合快速测试和学习。\")"
   ],
   "id": "d5a0ae49241bc45d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始加载CIFAR-10数据集...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "数据集下载完成！\n",
      "训练样本数: 1000\n",
      "测试样本数: 200\n",
      "使用设备: cuda\n",
      "模型参数数量: 136,874\n",
      "开始快速训练...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 114\u001B[0m\n\u001B[0;32m    111\u001B[0m correct \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    112\u001B[0m total \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m--> 114\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch_idx, (data, target) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_loader):\n\u001B[0;32m    115\u001B[0m     data, target \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mto(device), target\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m    117\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[1;32mE:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32mE:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    677\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32mE:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__getitems__\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__getitems__\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpossibly_batched_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n",
      "File \u001B[1;32mE:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torch\\utils\\data\\dataset.py:419\u001B[0m, in \u001B[0;36mSubset.__getitems__\u001B[1;34m(self, indices)\u001B[0m\n\u001B[0;32m    417\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices])  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m    418\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 419\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx]] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices]\n",
      "File \u001B[1;32mE:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torch\\utils\\data\\dataset.py:419\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    417\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices])  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m    418\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 419\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices]\n",
      "File \u001B[1;32mE:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torchvision\\datasets\\cifar.py:119\u001B[0m, in \u001B[0;36mCIFAR10.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m    116\u001B[0m img \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mfromarray(img)\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 119\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    121\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_transform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    122\u001B[0m     target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_transform(target)\n",
      "File \u001B[1;32mE:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001B[0m, in \u001B[0;36mCompose.__call__\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[0;32m     94\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransforms:\n\u001B[1;32m---> 95\u001B[0m         img \u001B[38;5;241m=\u001B[39m \u001B[43mt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "File \u001B[1;32mE:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001B[0m, in \u001B[0;36mToTensor.__call__\u001B[1;34m(self, pic)\u001B[0m\n\u001B[0;32m    129\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, pic):\n\u001B[0;32m    130\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    131\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m    132\u001B[0m \u001B[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    135\u001B[0m \u001B[38;5;124;03m        Tensor: Converted image.\u001B[39;00m\n\u001B[0;32m    136\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 137\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpic\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\avm\\ado\\envs\\py310\\lib\\site-packages\\torchvision\\transforms\\functional.py:168\u001B[0m, in \u001B[0;36mto_tensor\u001B[1;34m(pic)\u001B[0m\n\u001B[0;32m    166\u001B[0m \u001B[38;5;66;03m# handle PIL Image\u001B[39;00m\n\u001B[0;32m    167\u001B[0m mode_to_nptype \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mI\u001B[39m\u001B[38;5;124m\"\u001B[39m: np\u001B[38;5;241m.\u001B[39mint32, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mI;16\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m sys\u001B[38;5;241m.\u001B[39mbyteorder \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlittle\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mI;16B\u001B[39m\u001B[38;5;124m\"\u001B[39m: np\u001B[38;5;241m.\u001B[39mint16, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mF\u001B[39m\u001B[38;5;124m\"\u001B[39m: np\u001B[38;5;241m.\u001B[39mfloat32}\n\u001B[1;32m--> 168\u001B[0m img \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpic\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode_to_nptype\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpic\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muint8\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    170\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pic\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    171\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m255\u001B[39m \u001B[38;5;241m*\u001B[39m img\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Numpy is not available"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
